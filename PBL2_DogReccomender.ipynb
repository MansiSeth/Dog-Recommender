{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bf2343a",
   "metadata": {},
   "source": [
    "# Dog Recommendation System\n",
    "The system works by collecting data from users about their preferences and matching them with data about dogs, such as breed, size, and temperament. Users provide their preferences by answering a questionnaire that asks about their lifestyle, living situation, and preferences for a dog's size and temperament. The algorithm then matches the user's preferences with the characteristics of different dog breeds and recommends a few options that are likely to be a good fit for them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efae242",
   "metadata": {},
   "source": [
    "## Importing Libraries \n",
    "\n",
    "### numpy (imported as np):\n",
    "A popular numerical computation library that provides support for working with arrays, matrices, and mathematical functions.\n",
    "\n",
    "### pandas (imported as pd): \n",
    "A powerful data manipulation library that provides data structures like DataFrames and Series, which are commonly used for data analysis tasks.\n",
    "\n",
    "### seaborn (imported as sns):\n",
    "A popular data visualization library based on matplotlib that provides additional functionality for creating attractive statistical plots.\n",
    "\n",
    "### IPython.display:\n",
    "A module that provides utilities for displaying interactive output in IPython notebooks, such as display() function which can be used to show dataframes or plots.\n",
    "\n",
    "### sklearn.metrics.pairwise:\n",
    "A module from the popular machine learning library scikit-learn that provides implementations of distance and similarity metrics commonly used in recommendation systems, such as euclidean_distances and cosine_similarity, which are used to compute distances and similarities between data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "171e3233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bac358b",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "The dataset is scraped data from the American Kennel Club wesite a version of which is publically available on Kaggle. It contains 282 rows of unique dog breeds but has many missing values that will be dealt with later. The dataset has 18 columns for traits like shedding, height, weight, life expectancy etc.\n",
    "\n",
    "The group column categorizes each dog into one of 7 categories: toy, hound, terrier, working, sporting, non-sporting, herding and miscellaneous.\n",
    "\n",
    "'_value' in the name of the column indicates that the column has numeric values of 0.2,0.4,0.6,0.8 or 1, a higher value indicating a higher occurance of the category. Ex. a value of 1 in shedding_value indicates high shedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5503f5dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/hp/OneDrive/Documents/SEM6/Flexi/akcdata-master/akcdata-master/data/akcdata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the dataset into a pandas dataframe\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:/Users/hp/OneDrive/Documents/SEM6/Flexi/akcdata-master/akcdata-master/data/akcdata.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/hp/OneDrive/Documents/SEM6/Flexi/akcdata-master/akcdata-master/data/akcdata.csv'"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a pandas dataframe\n",
    "df = pd.read_csv('C:/Users/hp/OneDrive/Documents/SEM6/Flexi/akcdata-master/akcdata-master/data/akcdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a8efed",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dfe420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the height from inches to cm\n",
    "df['min_height'] = df['min_height'].apply(lambda x: x * 2.54)\n",
    "df['max_height'] = df['max_height'].apply(lambda x: x * 2.54)\n",
    "\n",
    "# Remove the conversion of weights from lbs to kg\n",
    "df['min_weight'] = df['min_weight'].apply(lambda x: x * 0.453592)\n",
    "df['max_weight'] = df['max_weight'].apply(lambda x: x * 0.453592)\n",
    "\n",
    "# Save the modified dataframe to a new csv file\n",
    "df.to_csv('modified_dog_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38391559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first few rows of the dataframe\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaac8a8",
   "metadata": {},
   "source": [
    "We now rename the first column of the DataFrame df from 'Unnamed: 0' to 'breed' using the rename() function from pandas. The columns parameter is used to specify the old column name as the key and the new column name as the value in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7229da6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the name of the first column to 'breed'\n",
    "df = df.rename(columns={'Unnamed: 0': 'breed'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b98e25",
   "metadata": {},
   "source": [
    "#### Removing Missing Values\n",
    "Now we check if there are any missing values (NaN or Null) in the DataFrame df and prints the total count of missing values for each column.\n",
    "\n",
    "Then, we remove any rows from df that contain missing values using the dropna() function, modifying df directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e9f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Drop any rows with missing values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cce73c",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "The pre-processing resulted in 187 rows of unique dog breeds which can further be analysed. \n",
    "\n",
    " We first print the datatypes using the dtypes attribute of a pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811aa001",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check the data types of the columns\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0219e19c",
   "metadata": {},
   "source": [
    "### Histogram \n",
    "The histplot() function from the seaborn library is then used to create a histogram of the distribution of the target variable 'popularity'. The data parameter is set to df to specify the DataFrame to be used, and the x parameter is set to 'popularity' to specify the column to be plotted on the x-axis. The bins parameter is set to 20 to specify the number of bins in the histogram. This operation creates a histogram plot of the distribution of the 'popularity' values in the DataFrame df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d267c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the distribution of the target variable\n",
    "sns.histplot(data=df, x='popularity', bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b428e8",
   "metadata": {},
   "source": [
    "### Pairplot \n",
    "The pairplot() function from the seaborn library is used to create a scatterplot matrix that shows the pairwise relationships between the target variable 'popularity' and other variables in the DataFrame df. \n",
    "\n",
    "The data parameter is set to df to specify the DataFrame to be used, and the vars parameter is set to a list of column names (['popularity', 'min_height', 'max_height', 'min_weight', 'max_weight']) to specify the variables to be plotted.\n",
    "\n",
    "This operation creates a scatterplot matrix that visualizes the relationships between the 'popularity' and the other variables in df, allowing for exploration of potential correlations or patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5678d736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the relationship between the target variable and other variables\n",
    "sns.pairplot(data=df, vars=['popularity', 'min_height', 'max_height', 'min_weight', 'max_weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3555dd70",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "We perform operations on some '_value' columns to obtain new featurs that are columns of ones and zeroes to be used in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58b28f3",
   "metadata": {},
   "source": [
    "### Shedding Feature\n",
    "We iterate over the columns in the DataFrame df to create three new columns in df with prefixes 'high_', 'medium_', and 'low_', respectively, followed by the original column name with '_value' removed. These new columns are used to categorize the values in the original column into high, medium, or low based on specific conditions.\n",
    "\n",
    "We apply lambda functions to the original column to categorize the values into high, medium, or low categories based on their values. The conditions for each category are defined as follows:\n",
    "- 'high_' prefix: values greater than or equal to 0.8\n",
    "- 'medium_' prefix: values between 0.4 and 0.8 (inclusive)\n",
    "- 'low_' prefix: values less than or equal to 0.4\n",
    "\n",
    "Next we modify the original column by applying another lambda function that converts the original values into a list containing the original value and 0. This operation effectively replaces the original values in the column with lists containing the original value and a 0 [original value, 0]\n",
    "\n",
    "Lastly, we select the columns 'shedding_value', 'shedding_category', 'high_shedding', 'medium_shedding', and 'low_shedding' from the DataFrame df and returns a new DataFrame containing only these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d45bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [col for col in df.columns if 'value' in col]:\n",
    "    df[('high_'+col).replace('_value','')] = df[col].apply(lambda x: x >= .8)\n",
    "    df[('medium_'+col).replace('_value','')] = df[col].apply(lambda x: .4 <= x <= .8)\n",
    "    df[('low_'+col).replace('_value','')] = df[col].apply(lambda x: x <= .4)\n",
    "    \n",
    "    df[col] = df[col].apply(lambda x: [x,0])\n",
    "\n",
    "    df[['shedding_value', 'shedding_category', 'high_shedding', 'medium_shedding', 'low_shedding']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f78ec87",
   "metadata": {},
   "source": [
    "### Height, Weight, Expectancy related Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed00152a",
   "metadata": {},
   "source": [
    "#### Creating columns for average values of height, weight, expectancy\n",
    "This code block calculates the average (mean) value for the columns 'height', 'weight', and 'expectancy' in the DataFrame df by taking the sum of the maximum and minimum values for each of these columns and dividing it by 2.\n",
    "\n",
    "The calculated average value is then assigned to a new column with the same name as the original column but without the prefix 'max_' or 'min_'. This operation effectively replaces the original columns 'height', 'weight', and 'expectancy' with the calculated average values, which could be useful for further analysis or modeling purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43218584",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['height','weight','expectancy']:\n",
    "    df[col] = (df['max_'+col] + df['min_'+col])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61b108f",
   "metadata": {},
   "source": [
    "#### height, weight, expectancy columns for relative position values based on percentile range\n",
    "\n",
    "We calculate percentiles for 'height', 'weight', and 'expectancy' columns in the DataFrame df using the describe() function.\n",
    "We create three binary columns ('high_'+col, 'medium_'+col, 'low_'+col) indicating whether the values are higher, within a certain range, or lower than the percentile values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a830ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['height','weight','expectancy']:\n",
    "    temp = df[col].describe(percentiles=[.2,.33,.4,.6,.67,.8])\n",
    "    df['high_'+col] = df[col].apply(lambda x: x > temp['67%'])\n",
    "    df['medium_'+col] = df[col].apply(lambda x: temp['33%'] < x < temp['67%'])\n",
    "    df['low_'+col] = df[col].apply(lambda x: x < temp['33%'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ebffa4",
   "metadata": {},
   "source": [
    "We then create new columns with '_value' suffix (height_value, weight_value, expectancy_value), assigning values based on percentile ranges, and converting them to a list with the original value as the first element and 0 as the second element.\n",
    "\n",
    "This operation categorizes the values into discrete bins based on percentiles and creates binary columns for relative position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a1a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "  df[col+'_value'] = df[col].apply(lambda x: '1' if x >= temp['80%'] else x)\n",
    "    df[col+'_value'] = df[col+'_value'].apply(lambda x: '.8' if ((type(x)!=str) and (x >= temp['60%']) and (x < temp['80%'])) else x)\n",
    "    df[col+'_value'] = df[col+'_value'].apply(lambda x: '.6' if ((type(x)!=str) and (x >= temp['40%']) and (x < temp['60%'])) else x)\n",
    "    df[col+'_value'] = df[col+'_value'].apply(lambda x: '.4' if ((type(x)!=str) and (x >= temp['20%']) and (x < temp['40%'])) else x)\n",
    "    df[col+'_value'] = df[col+'_value'].apply(lambda x: '.2' if ((type(x)!=str) and (x < temp['20%'])) else x) \n",
    "    \n",
    "\n",
    "    df[col+'_value'] = df[col+'_value'].apply(lambda x: [float(x),0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbee79d",
   "metadata": {},
   "source": [
    "We now display all the weight columns as a dataframe.\n",
    "\n",
    "\n",
    "\n",
    "- 'min_weight': contains the minimum weight in kg for a particular breed.\n",
    "\n",
    "- 'max_weight': contains the maximum weight in kg for a particular breed.\n",
    "\n",
    "- 'weight': is calculated as the average of 'min_weight' and 'max_weight', representing the estimated weight for a particular breed.\n",
    "\n",
    "- 'high_weight', 'medium_weight', 'low_weight': are binary columns indicating whether the estimated weight falls in the higher, medium, or lower range based on percentile values.\n",
    "\n",
    "- 'weight_value': contains values assigned based on percentile ranges for the estimated weight, converted to a list with the original value as the first element and 0 as the second element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cadcc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['min_weight', 'max_weight', 'weight', 'high_weight', 'medium_weight', 'low_weight', 'weight_value']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1704a056",
   "metadata": {},
   "source": [
    "We create a list of column names to be used as output columns. The list includes 'group' and 'temperament' as well as any column names from df that contain substrings 'min_', 'max_', or 'category'.\n",
    "\n",
    "- 'group': represents the group or category of the dog breed.\n",
    "- 'temperament': represents the temperament or behavior traits associated with the dog breed.\n",
    "- [col for col in df.columns if any([substr in col for substr in ['min_', 'max_', 'category']])]: dynamically generates a list of column names from df that contain 'min_', 'max_', or 'category' as substrings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf09b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cols = ['group', 'temperament'] + [col for col in df.columns if any([substr in col for substr in ['min_', 'max_', 'category']])]\n",
    "display(output_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57b7843",
   "metadata": {},
   "source": [
    "### Group Feature\n",
    "\n",
    "We define a function recommend_popular_dogs() that takes optional arguments group, low, medium, and high as input. The function is designed to recommend popular dog breeds based on specified criteria.\n",
    "\n",
    "The function first checks the types of the input arguments group, low, medium, and high, and converts them to lists if they are strings.\n",
    "\n",
    "The function then creates a sorted copy of df based on the 'popularity' column and assigns it to the temporary variable 'temp'.\n",
    "\n",
    "The function filters the 'temp' dataframe based on the criteria provided in the input arguments:\n",
    "If 'group' is provided, the 'temp' dataframe is filtered to include only rows where the 'group' column value matches any of the values in the 'group' input list.\n",
    "If 'low', 'medium', or 'high' lists are provided, the 'temp' dataframe is filtered based on the corresponding columns ('low_', 'medium_', 'high_') and values in the input lists.\n",
    "\n",
    "\n",
    "The function then prints the names of the recommended dog breeds, limited to a maximum of 10 breeds or the number of breeds available in 'temp', whichever is smaller.\n",
    "For each recommended dog breed, the function prints the breed name, description, and values from the 'output_cols' list. The function returns None as there is no explicit return statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8061cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_popular_dogs(group=[],low=[],medium=[],high=[]):\n",
    "\n",
    "    #converting arguments to lists if they are stringd\n",
    "    if type(group) == str:\n",
    "        group = [group]\n",
    "    if type(low) == str:\n",
    "        low = [low]\n",
    "    if type(medium) == str:\n",
    "        medium = [medium]\n",
    "    if type(high) == str:\n",
    "        high = [high]\n",
    "    \n",
    "    #sorting temp according to popularity\n",
    "    temp = df.sort_values('popularity')\n",
    "\n",
    "    #filter for input values\n",
    "    if len(group) > 0: #if group value is provided\n",
    "        temp = temp[temp['group'].isin(group)]#show rows where group value matches the input \n",
    "\n",
    "    if len(low) > 0: #if 'low_' input is given\n",
    "        for col in low:\n",
    "            temp = temp[temp['low_'+col]]#show rows where low_col value matches input value\n",
    "    if len(medium) > 0:\n",
    "        for col in medium:\n",
    "            temp = temp[temp['medium_'+col]]\n",
    "    if len(high) > 0:\n",
    "        for col in high:\n",
    "            temp = temp[temp['high_'+col]]\n",
    "    \n",
    "    \n",
    "    # limiting recomendations to top 10 dogs\n",
    "    num_dogs = min(10,len(temp))\n",
    "    \n",
    "\n",
    "    #printing recommended dogs\n",
    "    for i in range(num_dogs):\n",
    "        print('{}.'.format(i+1),temp['breed'].iloc[i])\n",
    "    \n",
    "    for i in range(num_dogs):\n",
    "        print()\n",
    "        print('{}.'.format(i+1),temp['breed'].iloc[i])\n",
    "        print(temp['description'].iloc[i])\n",
    "        print(temp[output_cols].iloc[i])\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69626bb7",
   "metadata": {},
   "source": [
    "We modify the 'group' column in the 'df' dataframe by applying a lambda function to each element in the column to remove 'Group' substring from values. The lambda function uses the 'replace()' method to remove the string 'Group' from the values in the 'group' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f48d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['group']=df['group'].apply(lambda x: x.replace('Group',''))\n",
    "\n",
    "#calling the defined function\n",
    "recommend_popular_dogs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426ab278",
   "metadata": {},
   "source": [
    "We call the 'recommend_popular_dogs()' with the 'group' parameter set to 'Toy'. This filters the 'df' dataframe to include only dog breeds belonging to the 'Toy' group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d5002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_popular_dogs(group='Toy ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd13204a",
   "metadata": {},
   "source": [
    "### One-Hot Encoding Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f02f5b6",
   "metadata": {},
   "source": [
    "#### Temperament Feature\n",
    "\n",
    "We split the temperament column using lambda function to get a list of strings. Then we store unique values from \"temperament list\" in a list called \"temperament_no_repeats\" using the set() function. \n",
    "\n",
    "\n",
    "We now create one-hot encoded columns for each unique temperament value using a lambda function. The lambda function iterates over the \"temperament_no_repeats\" list and checks if each value is present in the \"temperament list\" column. If a value is present, it is encoded as 1, otherwise 0. The result is stored in a new column called \"one-hot temperament\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df441018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the \"temperament\" column into a list of strings\n",
    "df['temperament list'] = df['temperament'].apply(lambda x: x.split(',') if type(x) == str else [])\n",
    "\n",
    "# Extract the unique temperament values\n",
    "temperament = []\n",
    "for i in df['temperament list']:\n",
    "    temperament.extend(i)\n",
    "temperament_no_repeats = set(temperament)\n",
    "\n",
    "# Create one-hot encoded columns for each unique temperament value\n",
    "df['one-hot temperament'] = df['temperament list'].apply(lambda x: [int(temperament in x) for temperament in temperament_no_repeats])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daa15e1",
   "metadata": {},
   "source": [
    "#### Group Feature\n",
    "\n",
    "We Extract the unique values from the \"group\" column using the unique() function, and store them in a list called \"group_no_repeats\".\n",
    "\n",
    "Then, we one-hot encoded columns for each unique group value using a lambda function. The lambda function iterates over the \"group_no_repeats\" list and checks if each value is present in the \"group\" column. If a value is present, it is encoded as 1, otherwise 0. The result is stored in a new column called \"one-hot group\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0048d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_no_repeats = df['group'].unique()\n",
    "df['one-hot group'] = df['group'].apply(lambda x: [int(group in x) for group in group_no_repeats])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5953580",
   "metadata": {},
   "source": [
    "The recommend_similar_dogs() function takes several arguments as input and converts them into lists if they are provided as strings.\n",
    "\n",
    "We Create a temporary dataframe temp by selecting columns from the original dataframe df based on the columns to ignore and filter temp based on the input arguments. \n",
    "\n",
    "\n",
    "Computes similarity scores between dogs in temp based on various columns using Euclidean distances and cosine similarities, and stores the results in a numpy array sims.\n",
    "Identifies the index of the input breed in temp and uses it to sort the similarity scores in descending order.\n",
    "Selects the top 10 similar breeds based on the similarity scores and stores their indices in breed_indices.\n",
    "Prints the list of recommended similar breeds with their descriptions and selected columns from temp.\n",
    "Note: The actual implementation may vary depending on the specific structure and content of the dataframe df, as well as the input arguments provided to the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996e2a51",
   "metadata": {},
   "source": [
    "## Similarity Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dda4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar_dogs(breed,group=[],low=[],medium=[],high=[],ignore=[],important=[]):\n",
    "\n",
    "    #converting to lists if input is string\n",
    "    if type(group) == str:\n",
    "        group = [group]\n",
    "    if type(low) == str:\n",
    "        low = [low]\n",
    "    if type(medium) == str:\n",
    "        medium = [medium]\n",
    "    if type(high) == str:\n",
    "        high = [high]\n",
    "    if type(ignore) == str:\n",
    "        ignore = [ignore]\n",
    "    \n",
    "    \n",
    "    #creating a temporary dataframe \n",
    "    temp_cols = set(df.columns) - set(ignore)\n",
    "    temp = df[temp_cols]\n",
    "\n",
    "\n",
    "    if len(group) > 0: #if 'group' inputs are given\n",
    "        temp = temp[(temp['breed']==breed)|(temp['group'].isin(group))] #filter only those values whose values are eqult to input 'group'\n",
    "    if len(low) > 0:\n",
    "        for col in low:\n",
    "            temp = temp[(temp['breed']==breed)|(temp['low_'+col])]\n",
    "    if len(medium) > 0:\n",
    "        for col in medium:\n",
    "            temp = temp[(temp['breed']==breed)|(temp['medium_'+col])]\n",
    "    if len(high) > 0:\n",
    "        for col in high:\n",
    "            temp = temp[(temp['breed']==breed)|(temp['high_'+col])]\n",
    "    temp = temp.reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e27568",
   "metadata": {},
   "source": [
    "We start by initializing a 2D array with zeroes. It's length is as much as the length of 'temp' list.\n",
    "\n",
    "We iterate over all columns of temp that have a substring 'value'. If a given column is in the 'important' input list, the similarity score is calculated and added to sims array. If the given column is not in the 'important' input list,the similarity score is calculated with a different formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba85a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = np.zeros([len(temp),len(temp)]) #initialized a 2D array with zeroes. It's length is as much as the length of 'temp' list \n",
    "\n",
    "\n",
    "    for col in [col for col in temp.columns if 'value' in col]: #iterating over all columns with substring \"value\" in temp\n",
    "        if col in important:\n",
    "            sims += 5*(1-np.array(euclidean_distances(temp[col].tolist(),temp[col].tolist())))\n",
    "        else:\n",
    "            sims += (1-np.array(euclidean_distances(temp[col].tolist(),temp[col].tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fb88c7",
   "metadata": {},
   "source": [
    "We iterate over one-got temperament and group columns to find similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4667b514",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['one-hot temperament','one-hot group']:\n",
    "        if col in important:\n",
    "            sims += 5*np.array(cosine_similarity(temp[col].tolist(),temp[col].tolist()))\n",
    "        else:\n",
    "            sims += np.array(cosine_similarity(temp[col].tolist(),temp[col].tolist()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354a64aa",
   "metadata": {},
   "source": [
    "We now find the index of the given breed in the dataframe 'temp' and create 'sims' list tha that has index and similarity score. \n",
    "We sort sims using a lambda function to display a decreasing order of similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5527e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = temp[temp['breed']==breed].index\n",
    "    sims = list(enumerate(sims[idx][0]))\n",
    "    \n",
    "    sims = sorted(sims, key=lambda x: x[1], reverse=True) #decending order sorting of sims\n",
    "\n",
    "    num_dogs = min(10,len(temp))# checking which is lesser; length of temp or 10\n",
    "    sims = sims[:num_dogs+1] # slicing to get top 10 or top len(temp) if it's lesser than 10\n",
    "\n",
    "    breed_indices = [i[0] for i in sims] #breed_indices is all indices in sims\n",
    "    \n",
    "    n = 0\n",
    "    for i in breed_indices:\n",
    "        if n == 0:\n",
    "            print('Selected:'.format(n),temp['breed'].iloc[i])\n",
    "        else:\n",
    "            print('{}.'.format(n),temp['breed'].iloc[i])\n",
    "        n += 1\n",
    "    \n",
    "    n = 0\n",
    "    for i in breed_indices:\n",
    "        print()\n",
    "        if n == 0:\n",
    "            print('Selected:'.format(n),temp['breed'].iloc[i])\n",
    "        else:\n",
    "            print('{}.'.format(n),temp['breed'].iloc[i])\n",
    "        print(temp['description'].iloc[i])\n",
    "        print(temp[output_cols].iloc[i])\n",
    "        n += 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e764c3",
   "metadata": {},
   "source": [
    "Testing the function with given input lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2679c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_similar_dogs('Shiba Inu', high=['demeanor' , 'trainability'],important=['group','height','weight'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
